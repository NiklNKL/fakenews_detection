{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_utils import load_and_concatenate_parquet_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>donald trump respond mockery fake swedish atta...</td>\n",
       "      <td>1</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tweetwavethis time true pantstweetwave anthony...</td>\n",
       "      <td>1</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rubio prospect trump president worrisome reute...</td>\n",
       "      <td>0</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump lifts cyber command status boost cyber d...</td>\n",
       "      <td>0</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>big republican lie economy tear apart minute v...</td>\n",
       "      <td>1</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63116</th>\n",
       "      <td>half briton want stay eu polledinburgh reuters...</td>\n",
       "      <td>0</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63117</th>\n",
       "      <td>bill hillary clinton inc sale right pricein sp...</td>\n",
       "      <td>1</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63118</th>\n",
       "      <td>orlando gunman shoot time autopsy find new yor...</td>\n",
       "      <td>0</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63119</th>\n",
       "      <td>lethal gap supreme court handle death penalty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63120</th>\n",
       "      <td>poll world overwhelmingly love president obama...</td>\n",
       "      <td>1</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63121 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label label_names\n",
       "0      donald trump respond mockery fake swedish atta...      1        real\n",
       "1      tweetwavethis time true pantstweetwave anthony...      1        real\n",
       "2      rubio prospect trump president worrisome reute...      0        fake\n",
       "3      trump lifts cyber command status boost cyber d...      0        fake\n",
       "4      big republican lie economy tear apart minute v...      1        real\n",
       "...                                                  ...    ...         ...\n",
       "63116  half briton want stay eu polledinburgh reuters...      0        fake\n",
       "63117  bill hillary clinton inc sale right pricein sp...      1        real\n",
       "63118  orlando gunman shoot time autopsy find new yor...      0        fake\n",
       "63119  lethal gap supreme court handle death penalty ...      0        fake\n",
       "63120  poll world overwhelmingly love president obama...      1        real\n",
       "\n",
       "[63121 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df  = load_and_concatenate_parquet_files('data/preprocessed_big_training_df')\n",
    "\n",
    "df = df.rename(columns={'preprocessed_text': 'text'})\n",
    "df[\"label_names\"] = df[\"label\"].apply(lambda x: \"real\" if x == 1 else \"fake\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44184, 3), (12624, 3), (6313, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,test      = train_test_split(df,test_size=0.3,stratify=df['label'])\n",
    "test,validation = train_test_split(test,test_size=1/3,stratify=test['label'])\n",
    "train.shape, test.shape, validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_names'],\n",
       "        num_rows: 44184\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_names'],\n",
       "        num_rows: 12624\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_names'],\n",
       "        num_rows: 6313\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DatasetDict(\n",
    "    {'train':Dataset.from_pandas(train,preserve_index=False),\n",
    "     'test':Dataset.from_pandas(test,preserve_index=False),\n",
    "     'validation': Dataset.from_pandas(validation,preserve_index=False)\n",
    "     }    \n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fake': 0, 'real': 1}, {0: 'fake', 1: 'real'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {x['label_names']:x['label'] for x in dataset['train']}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "label2id, id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DebertaV2Tokenizer\n",
    "# Load dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the evaluation metric\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    result = {}\n",
    "    for metric in [accuracy_metric, f1_metric, precision_metric, recall_metric]:\n",
    "        result.update(metric.compute(predictions=predictions, references=labels))\n",
    "    return result\n",
    "\n",
    "# Fine-tuning function\n",
    "def fine_tune_model(model_ckpt, dataset, output_dir, training_batch_size=32, checkpoint=None, epochs=5):\n",
    "    print(f\"Using Model: {model_ckpt}\")\n",
    "    print(f\"Tokenizing Data\")\n",
    "    # Tokenizer and dataset preparation\n",
    "    if model_ckpt == \"microsoft/deberta-v3-base\":\n",
    "        tokenizer = DebertaV2Tokenizer.from_pretrained(model_ckpt, use_fast=True)\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_ckpt) \n",
    "    def tokenize_and_format(batch):\n",
    "        tokens = tokenizer(batch['text'], padding=True, truncation=True)\n",
    "        # Convert to PyTorch tensors and move to the correct device\n",
    "        tokens = {key: torch.tensor(val).to(device) for key, val in tokens.items()}\n",
    "        tokens['labels'] = torch.tensor(batch['label']).to(device)\n",
    "        return tokens\n",
    "    tokenized_dataset = dataset.map(tokenize_and_format, batched=True)\n",
    "\n",
    "    # Config and model\n",
    "    config = AutoConfig.from_pretrained(model_ckpt, num_labels=2)  # Adjust num_labels if needed\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, config=config).to(device)\n",
    "        \n",
    "    if model_ckpt == \"distilbert-base-uncased\":\n",
    "        target_modules = [\"q_lin\", \"k_lin\",\"v_lin\"]\n",
    "    elif model_ckpt == \"microsoft/deberta-v3-base\":\n",
    "        target_modules = None\n",
    "    else:\n",
    "        target_modules = [\"query\", \"value\"]\n",
    "\n",
    "    \n",
    "    # PEFT: LoRA\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=\"SEQ_CLS\",\n",
    "        r=8,  # Smaller rank to reduce file size\n",
    "        lora_alpha=32,  # Adjust scaling factor\n",
    "        lora_dropout=0.1,\n",
    "        target_modules=target_modules\n",
    "    )\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    \n",
    "    if checkpoint:\n",
    "        print(f\"Loading LoRA weights from {checkpoint}\")\n",
    "        model.load_state_dict(torch.load(checkpoint), strict=False)\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,  # Adjust based on needs\n",
    "        per_device_train_batch_size=training_batch_size,\n",
    "        per_device_eval_batch_size=training_batch_size,\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "        save_total_limit=4,  # Limit checkpoints\n",
    "        fp16=True,  # Mixed precision for speed\n",
    "        logging_steps=50,\n",
    "        report_to=\"tensorboard\",\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        warmup_steps=500,\n",
    "    )\n",
    "    \n",
    "    # Trainer setup\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"test\"],\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    print(\"Starting Training\")\n",
    "    # Train\n",

    "    trainer.train(resume_from_checkpoint=checkpoint != None)\n",
    "    test_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "    print(f\"Test Results: {test_results}\")\n",
    "    # Save LoRA-only model\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Finished training {model_ckpt}. Model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Model: bert-base-uncased\n",
      "Tokenizing Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_checkpoints = [\n",
    "    \"bert-base-uncased\",\n",
    "    # \"distilbert-base-uncased\",\n",
    "    \"roberta-base\",\n",
    "    \"microsoft/deberta-v3-base\"\n",
    "]\n",
    "\n",
    "# Iterate over models\n",
    "for model_ckpt in model_checkpoints:\n",
    "    output_dir = f\"models/{model_ckpt.replace('/', '_')}\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    fine_tune_model(model_ckpt, dataset, output_dir, training_batch_size=32, epochs=5)\n",
    "\n",
    "# checkpoint=\"/home/developing_nacho/fhdw/knowledge_engineering/fakenews_detection/models/distilbert-base-uncased/checkpoint-3455/rng_state.pth\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
