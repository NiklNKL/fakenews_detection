{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 6905,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.036205648081100654,
      "grad_norm": 2.7148594856262207,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.6917,
      "step": 50
    },
    {
      "epoch": 0.07241129616220131,
      "grad_norm": 0.5708737373352051,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.6889,
      "step": 100
    },
    {
      "epoch": 0.10861694424330195,
      "grad_norm": 1.2754309177398682,
      "learning_rate": 6e-06,
      "loss": 0.686,
      "step": 150
    },
    {
      "epoch": 0.14482259232440262,
      "grad_norm": 1.870444416999817,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.6839,
      "step": 200
    },
    {
      "epoch": 0.18102824040550325,
      "grad_norm": 0.9312920570373535,
      "learning_rate": 1e-05,
      "loss": 0.6764,
      "step": 250
    },
    {
      "epoch": 0.2172338884866039,
      "grad_norm": 0.9065023064613342,
      "learning_rate": 1.2e-05,
      "loss": 0.6504,
      "step": 300
    },
    {
      "epoch": 0.25343953656770457,
      "grad_norm": 3.514132022857666,
      "learning_rate": 1.4e-05,
      "loss": 0.5289,
      "step": 350
    },
    {
      "epoch": 0.28964518464880523,
      "grad_norm": 3.317500352859497,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.4354,
      "step": 400
    },
    {
      "epoch": 0.3258508327299059,
      "grad_norm": 2.4045937061309814,
      "learning_rate": 1.796e-05,
      "loss": 0.3996,
      "step": 450
    },
    {
      "epoch": 0.3620564808110065,
      "grad_norm": 6.3762102127075195,
      "learning_rate": 1.9960000000000002e-05,
      "loss": 0.397,
      "step": 500
    },
    {
      "epoch": 0.39826212889210716,
      "grad_norm": 4.988833904266357,
      "learning_rate": 1.9846994535519127e-05,
      "loss": 0.3489,
      "step": 550
    },
    {
      "epoch": 0.4344677769732078,
      "grad_norm": 9.935163497924805,
      "learning_rate": 1.9690866510538645e-05,
      "loss": 0.3647,
      "step": 600
    },
    {
      "epoch": 0.4706734250543085,
      "grad_norm": 4.096523761749268,
      "learning_rate": 1.953473848555816e-05,
      "loss": 0.3378,
      "step": 650
    },
    {
      "epoch": 0.5068790731354091,
      "grad_norm": 10.1719331741333,
      "learning_rate": 1.9378610460577677e-05,
      "loss": 0.3083,
      "step": 700
    },
    {
      "epoch": 0.5430847212165097,
      "grad_norm": 3.403839588165283,
      "learning_rate": 1.922248243559719e-05,
      "loss": 0.3302,
      "step": 750
    },
    {
      "epoch": 0.5792903692976105,
      "grad_norm": 8.544564247131348,
      "learning_rate": 1.906635441061671e-05,
      "loss": 0.2953,
      "step": 800
    },
    {
      "epoch": 0.6154960173787111,
      "grad_norm": 12.546561241149902,
      "learning_rate": 1.891334894613583e-05,
      "loss": 0.2796,
      "step": 850
    },
    {
      "epoch": 0.6517016654598118,
      "grad_norm": 5.997800827026367,
      "learning_rate": 1.875722092115535e-05,
      "loss": 0.2524,
      "step": 900
    },
    {
      "epoch": 0.6879073135409124,
      "grad_norm": 6.596883773803711,
      "learning_rate": 1.8601092896174863e-05,
      "loss": 0.2568,
      "step": 950
    },
    {
      "epoch": 0.724112961622013,
      "grad_norm": 7.353546619415283,
      "learning_rate": 1.844496487119438e-05,
      "loss": 0.271,
      "step": 1000
    },
    {
      "epoch": 0.7603186097031137,
      "grad_norm": 4.09451961517334,
      "learning_rate": 1.82888368462139e-05,
      "loss": 0.2479,
      "step": 1050
    },
    {
      "epoch": 0.7965242577842143,
      "grad_norm": 20.660076141357422,
      "learning_rate": 1.8132708821233413e-05,
      "loss": 0.2179,
      "step": 1100
    },
    {
      "epoch": 0.832729905865315,
      "grad_norm": 5.3475422859191895,
      "learning_rate": 1.7976580796252928e-05,
      "loss": 0.213,
      "step": 1150
    },
    {
      "epoch": 0.8689355539464156,
      "grad_norm": 4.964682579040527,
      "learning_rate": 1.7820452771272445e-05,
      "loss": 0.2127,
      "step": 1200
    },
    {
      "epoch": 0.9051412020275162,
      "grad_norm": 4.876798629760742,
      "learning_rate": 1.766432474629196e-05,
      "loss": 0.2329,
      "step": 1250
    },
    {
      "epoch": 0.941346850108617,
      "grad_norm": 10.829814910888672,
      "learning_rate": 1.7508196721311478e-05,
      "loss": 0.2156,
      "step": 1300
    },
    {
      "epoch": 0.9775524981897176,
      "grad_norm": 9.500218391418457,
      "learning_rate": 1.7352068696330992e-05,
      "loss": 0.1874,
      "step": 1350
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9259347275031685,
      "eval_f1": 0.920970332178176,
      "eval_loss": 0.19028930366039276,
      "eval_precision": 0.883698296836983,
      "eval_recall": 0.9615248852806213,
      "eval_runtime": 48.4996,
      "eval_samples_per_second": 260.291,
      "eval_steps_per_second": 8.144,
      "step": 1381
    },
    {
      "epoch": 1.0137581462708183,
      "grad_norm": 18.021974563598633,
      "learning_rate": 1.719594067135051e-05,
      "loss": 0.1857,
      "step": 1400
    },
    {
      "epoch": 1.0499637943519189,
      "grad_norm": 3.7405858039855957,
      "learning_rate": 1.7039812646370024e-05,
      "loss": 0.1914,
      "step": 1450
    },
    {
      "epoch": 1.0861694424330195,
      "grad_norm": 9.240911483764648,
      "learning_rate": 1.688368462138954e-05,
      "loss": 0.1808,
      "step": 1500
    },
    {
      "epoch": 1.12237509051412,
      "grad_norm": 9.07755184173584,
      "learning_rate": 1.6727556596409056e-05,
      "loss": 0.1629,
      "step": 1550
    },
    {
      "epoch": 1.158580738595221,
      "grad_norm": 6.776610374450684,
      "learning_rate": 1.6571428571428574e-05,
      "loss": 0.1678,
      "step": 1600
    },
    {
      "epoch": 1.1947863866763215,
      "grad_norm": 8.662544250488281,
      "learning_rate": 1.641530054644809e-05,
      "loss": 0.1422,
      "step": 1650
    },
    {
      "epoch": 1.2309920347574221,
      "grad_norm": 5.696075916290283,
      "learning_rate": 1.6259172521467606e-05,
      "loss": 0.1649,
      "step": 1700
    },
    {
      "epoch": 1.2671976828385227,
      "grad_norm": 4.615222930908203,
      "learning_rate": 1.610304449648712e-05,
      "loss": 0.1202,
      "step": 1750
    },
    {
      "epoch": 1.3034033309196236,
      "grad_norm": 7.483365535736084,
      "learning_rate": 1.5946916471506638e-05,
      "loss": 0.1788,
      "step": 1800
    },
    {
      "epoch": 1.3396089790007242,
      "grad_norm": 15.910968780517578,
      "learning_rate": 1.5790788446526153e-05,
      "loss": 0.1629,
      "step": 1850
    },
    {
      "epoch": 1.3758146270818248,
      "grad_norm": 5.21762752532959,
      "learning_rate": 1.563466042154567e-05,
      "loss": 0.1718,
      "step": 1900
    },
    {
      "epoch": 1.4120202751629254,
      "grad_norm": 1.4031243324279785,
      "learning_rate": 1.5478532396565185e-05,
      "loss": 0.1255,
      "step": 1950
    },
    {
      "epoch": 1.448225923244026,
      "grad_norm": 6.4762468338012695,
      "learning_rate": 1.53224043715847e-05,
      "loss": 0.1281,
      "step": 2000
    },
    {
      "epoch": 1.4844315713251266,
      "grad_norm": 9.130478858947754,
      "learning_rate": 1.5166276346604217e-05,
      "loss": 0.1588,
      "step": 2050
    },
    {
      "epoch": 1.5206372194062274,
      "grad_norm": 8.127883911132812,
      "learning_rate": 1.5010148321623731e-05,
      "loss": 0.1246,
      "step": 2100
    },
    {
      "epoch": 1.556842867487328,
      "grad_norm": 13.514156341552734,
      "learning_rate": 1.4854020296643247e-05,
      "loss": 0.1218,
      "step": 2150
    },
    {
      "epoch": 1.5930485155684286,
      "grad_norm": 5.000587463378906,
      "learning_rate": 1.4697892271662763e-05,
      "loss": 0.1521,
      "step": 2200
    },
    {
      "epoch": 1.6292541636495295,
      "grad_norm": 6.34118127822876,
      "learning_rate": 1.4541764246682281e-05,
      "loss": 0.1552,
      "step": 2250
    },
    {
      "epoch": 1.66545981173063,
      "grad_norm": 8.248339653015137,
      "learning_rate": 1.4385636221701797e-05,
      "loss": 0.1069,
      "step": 2300
    },
    {
      "epoch": 1.7016654598117307,
      "grad_norm": 8.672628402709961,
      "learning_rate": 1.4229508196721313e-05,
      "loss": 0.1216,
      "step": 2350
    },
    {
      "epoch": 1.7378711078928313,
      "grad_norm": 11.1293306350708,
      "learning_rate": 1.407338017174083e-05,
      "loss": 0.1303,
      "step": 2400
    },
    {
      "epoch": 1.7740767559739319,
      "grad_norm": 6.928720951080322,
      "learning_rate": 1.3917252146760345e-05,
      "loss": 0.1283,
      "step": 2450
    },
    {
      "epoch": 1.8102824040550325,
      "grad_norm": 9.155132293701172,
      "learning_rate": 1.3761124121779862e-05,
      "loss": 0.1115,
      "step": 2500
    },
    {
      "epoch": 1.846488052136133,
      "grad_norm": 20.47231674194336,
      "learning_rate": 1.3604996096799376e-05,
      "loss": 0.13,
      "step": 2550
    },
    {
      "epoch": 1.882693700217234,
      "grad_norm": 8.82052230834961,
      "learning_rate": 1.3448868071818892e-05,
      "loss": 0.1267,
      "step": 2600
    },
    {
      "epoch": 1.9188993482983345,
      "grad_norm": 25.412458419799805,
      "learning_rate": 1.3292740046838408e-05,
      "loss": 0.1201,
      "step": 2650
    },
    {
      "epoch": 1.9551049963794354,
      "grad_norm": 6.162727355957031,
      "learning_rate": 1.3136612021857924e-05,
      "loss": 0.1227,
      "step": 2700
    },
    {
      "epoch": 1.991310644460536,
      "grad_norm": 16.571767807006836,
      "learning_rate": 1.298048399687744e-05,
      "loss": 0.1248,
      "step": 2750
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9587294043092522,
      "eval_f1": 0.9547310800243288,
      "eval_loss": 0.12057903409004211,
      "eval_precision": 0.9402704090364539,
      "eval_recall": 0.969643487469114,
      "eval_runtime": 44.3642,
      "eval_samples_per_second": 284.554,
      "eval_steps_per_second": 8.904,
      "step": 2762
    },
    {
      "epoch": 2.0275162925416366,
      "grad_norm": 9.625335693359375,
      "learning_rate": 1.2824355971896956e-05,
      "loss": 0.1195,
      "step": 2800
    },
    {
      "epoch": 2.063721940622737,
      "grad_norm": 9.020182609558105,
      "learning_rate": 1.2668227946916472e-05,
      "loss": 0.1273,
      "step": 2850
    },
    {
      "epoch": 2.0999275887038378,
      "grad_norm": 8.444406509399414,
      "learning_rate": 1.251209992193599e-05,
      "loss": 0.1171,
      "step": 2900
    },
    {
      "epoch": 2.1361332367849384,
      "grad_norm": 6.096272945404053,
      "learning_rate": 1.2359094457455114e-05,
      "loss": 0.1103,
      "step": 2950
    },
    {
      "epoch": 2.172338884866039,
      "grad_norm": 19.190855026245117,
      "learning_rate": 1.220296643247463e-05,
      "loss": 0.1176,
      "step": 3000
    },
    {
      "epoch": 2.2085445329471396,
      "grad_norm": 8.828507423400879,
      "learning_rate": 1.2046838407494146e-05,
      "loss": 0.1448,
      "step": 3050
    },
    {
      "epoch": 2.24475018102824,
      "grad_norm": 4.8295817375183105,
      "learning_rate": 1.1890710382513662e-05,
      "loss": 0.1173,
      "step": 3100
    },
    {
      "epoch": 2.2809558291093412,
      "grad_norm": Infinity,
      "learning_rate": 1.173770491803279e-05,
      "loss": 0.1142,
      "step": 3150
    },
    {
      "epoch": 2.317161477190442,
      "grad_norm": 12.565834045410156,
      "learning_rate": 1.1581576893052304e-05,
      "loss": 0.1185,
      "step": 3200
    },
    {
      "epoch": 2.3533671252715425,
      "grad_norm": 15.726005554199219,
      "learning_rate": 1.142544886807182e-05,
      "loss": 0.0996,
      "step": 3250
    },
    {
      "epoch": 2.389572773352643,
      "grad_norm": 25.208335876464844,
      "learning_rate": 1.1269320843091336e-05,
      "loss": 0.1339,
      "step": 3300
    },
    {
      "epoch": 2.4257784214337437,
      "grad_norm": 6.925796031951904,
      "learning_rate": 1.1113192818110852e-05,
      "loss": 0.1045,
      "step": 3350
    },
    {
      "epoch": 2.4619840695148443,
      "grad_norm": 10.23406982421875,
      "learning_rate": 1.0957064793130368e-05,
      "loss": 0.0948,
      "step": 3400
    },
    {
      "epoch": 2.498189717595945,
      "grad_norm": 8.85688591003418,
      "learning_rate": 1.0800936768149884e-05,
      "loss": 0.0965,
      "step": 3450
    },
    {
      "epoch": 2.5343953656770455,
      "grad_norm": 9.27175521850586,
      "learning_rate": 1.06448087431694e-05,
      "loss": 0.0991,
      "step": 3500
    },
    {
      "epoch": 2.5706010137581465,
      "grad_norm": 9.238960266113281,
      "learning_rate": 1.0488680718188914e-05,
      "loss": 0.1003,
      "step": 3550
    },
    {
      "epoch": 2.606806661839247,
      "grad_norm": 16.051767349243164,
      "learning_rate": 1.033255269320843e-05,
      "loss": 0.1066,
      "step": 3600
    },
    {
      "epoch": 2.6430123099203477,
      "grad_norm": 1.8041406869888306,
      "learning_rate": 1.0176424668227948e-05,
      "loss": 0.108,
      "step": 3650
    },
    {
      "epoch": 2.6792179580014484,
      "grad_norm": 15.170029640197754,
      "learning_rate": 1.0020296643247464e-05,
      "loss": 0.1084,
      "step": 3700
    },
    {
      "epoch": 2.715423606082549,
      "grad_norm": 20.913991928100586,
      "learning_rate": 9.864168618266979e-06,
      "loss": 0.1124,
      "step": 3750
    },
    {
      "epoch": 2.7516292541636496,
      "grad_norm": 2.758425235748291,
      "learning_rate": 9.708040593286495e-06,
      "loss": 0.1064,
      "step": 3800
    },
    {
      "epoch": 2.78783490224475,
      "grad_norm": 11.414790153503418,
      "learning_rate": 9.551912568306013e-06,
      "loss": 0.0989,
      "step": 3850
    },
    {
      "epoch": 2.8240405503258508,
      "grad_norm": 6.23506498336792,
      "learning_rate": 9.395784543325529e-06,
      "loss": 0.1018,
      "step": 3900
    },
    {
      "epoch": 2.8602461984069514,
      "grad_norm": 5.585665225982666,
      "learning_rate": 9.239656518345043e-06,
      "loss": 0.1001,
      "step": 3950
    },
    {
      "epoch": 2.896451846488052,
      "grad_norm": 6.963620185852051,
      "learning_rate": 9.083528493364559e-06,
      "loss": 0.1186,
      "step": 4000
    },
    {
      "epoch": 2.9326574945691526,
      "grad_norm": 3.279306411743164,
      "learning_rate": 8.927400468384075e-06,
      "loss": 0.115,
      "step": 4050
    },
    {
      "epoch": 2.968863142650253,
      "grad_norm": 11.510857582092285,
      "learning_rate": 8.771272443403591e-06,
      "loss": 0.0965,
      "step": 4100
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9639575411913816,
      "eval_f1": 0.9598092041339105,
      "eval_loss": 0.10510750114917755,
      "eval_precision": 0.9607427055702917,
      "eval_recall": 0.9588775150017649,
      "eval_runtime": 42.2574,
      "eval_samples_per_second": 298.741,
      "eval_steps_per_second": 9.347,
      "step": 4143
    },
    {
      "epoch": 3.0050687907313542,
      "grad_norm": 8.58773136138916,
      "learning_rate": 8.615144418423109e-06,
      "loss": 0.0884,
      "step": 4150
    },
    {
      "epoch": 3.041274438812455,
      "grad_norm": 8.037107467651367,
      "learning_rate": 8.459016393442623e-06,
      "loss": 0.1071,
      "step": 4200
    },
    {
      "epoch": 3.0774800868935555,
      "grad_norm": 10.777761459350586,
      "learning_rate": 8.30288836846214e-06,
      "loss": 0.1018,
      "step": 4250
    },
    {
      "epoch": 3.113685734974656,
      "grad_norm": 7.822970867156982,
      "learning_rate": 8.146760343481655e-06,
      "loss": 0.0867,
      "step": 4300
    },
    {
      "epoch": 3.1498913830557567,
      "grad_norm": 14.260025978088379,
      "learning_rate": 7.990632318501172e-06,
      "loss": 0.1219,
      "step": 4350
    },
    {
      "epoch": 3.1860970311368573,
      "grad_norm": 15.290081977844238,
      "learning_rate": 7.834504293520688e-06,
      "loss": 0.1002,
      "step": 4400
    },
    {
      "epoch": 3.222302679217958,
      "grad_norm": 6.856502532958984,
      "learning_rate": 7.678376268540204e-06,
      "loss": 0.0936,
      "step": 4450
    },
    {
      "epoch": 3.2585083272990585,
      "grad_norm": 8.474732398986816,
      "learning_rate": 7.52224824355972e-06,
      "loss": 0.0901,
      "step": 4500
    },
    {
      "epoch": 3.2947139753801595,
      "grad_norm": 14.627904891967773,
      "learning_rate": 7.366120218579236e-06,
      "loss": 0.108,
      "step": 4550
    },
    {
      "epoch": 3.33091962346126,
      "grad_norm": 4.806167125701904,
      "learning_rate": 7.209992193598752e-06,
      "loss": 0.0964,
      "step": 4600
    },
    {
      "epoch": 3.3671252715423607,
      "grad_norm": 6.355810165405273,
      "learning_rate": 7.053864168618267e-06,
      "loss": 0.073,
      "step": 4650
    },
    {
      "epoch": 3.4033309196234613,
      "grad_norm": 14.218207359313965,
      "learning_rate": 6.897736143637783e-06,
      "loss": 0.0975,
      "step": 4700
    },
    {
      "epoch": 3.439536567704562,
      "grad_norm": 0.9005069732666016,
      "learning_rate": 6.741608118657299e-06,
      "loss": 0.1139,
      "step": 4750
    },
    {
      "epoch": 3.4757422157856626,
      "grad_norm": 10.717206001281738,
      "learning_rate": 6.585480093676816e-06,
      "loss": 0.1037,
      "step": 4800
    },
    {
      "epoch": 3.511947863866763,
      "grad_norm": 8.637320518493652,
      "learning_rate": 6.429352068696331e-06,
      "loss": 0.1068,
      "step": 4850
    },
    {
      "epoch": 3.5481535119478638,
      "grad_norm": 2.0815484523773193,
      "learning_rate": 6.2732240437158475e-06,
      "loss": 0.0955,
      "step": 4900
    },
    {
      "epoch": 3.5843591600289644,
      "grad_norm": 16.140905380249023,
      "learning_rate": 6.1170960187353635e-06,
      "loss": 0.101,
      "step": 4950
    },
    {
      "epoch": 3.620564808110065,
      "grad_norm": 6.710884094238281,
      "learning_rate": 5.96096799375488e-06,
      "loss": 0.0774,
      "step": 5000
    },
    {
      "epoch": 3.6567704561911656,
      "grad_norm": 8.55573844909668,
      "learning_rate": 5.804839968774395e-06,
      "loss": 0.1042,
      "step": 5050
    },
    {
      "epoch": 3.6929761042722666,
      "grad_norm": 4.994393825531006,
      "learning_rate": 5.648711943793912e-06,
      "loss": 0.0826,
      "step": 5100
    },
    {
      "epoch": 3.7291817523533672,
      "grad_norm": 10.067227363586426,
      "learning_rate": 5.492583918813428e-06,
      "loss": 0.0994,
      "step": 5150
    },
    {
      "epoch": 3.765387400434468,
      "grad_norm": 7.521557331085205,
      "learning_rate": 5.336455893832944e-06,
      "loss": 0.1101,
      "step": 5200
    },
    {
      "epoch": 3.8015930485155685,
      "grad_norm": 3.5942602157592773,
      "learning_rate": 5.180327868852459e-06,
      "loss": 0.1029,
      "step": 5250
    },
    {
      "epoch": 3.837798696596669,
      "grad_norm": 4.165254592895508,
      "learning_rate": 5.027322404371585e-06,
      "loss": 0.0943,
      "step": 5300
    },
    {
      "epoch": 3.8740043446777697,
      "grad_norm": 11.774685859680176,
      "learning_rate": 4.871194379391101e-06,
      "loss": 0.1007,
      "step": 5350
    },
    {
      "epoch": 3.9102099927588703,
      "grad_norm": 16.251678466796875,
      "learning_rate": 4.7150663544106175e-06,
      "loss": 0.0851,
      "step": 5400
    },
    {
      "epoch": 3.946415640839971,
      "grad_norm": 4.566272735595703,
      "learning_rate": 4.558938329430133e-06,
      "loss": 0.0862,
      "step": 5450
    },
    {
      "epoch": 3.982621288921072,
      "grad_norm": 4.301578998565674,
      "learning_rate": 4.402810304449649e-06,
      "loss": 0.1031,
      "step": 5500
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9665716096324461,
      "eval_f1": 0.9631505413901502,
      "eval_loss": 0.10014718770980835,
      "eval_precision": 0.9531628067749741,
      "eval_recall": 0.9733498058595129,
      "eval_runtime": 42.6707,
      "eval_samples_per_second": 295.847,
      "eval_steps_per_second": 9.257,
      "step": 5524
    },
    {
      "epoch": 4.0188269370021725,
      "grad_norm": 1.6220924854278564,
      "learning_rate": 4.246682279469166e-06,
      "loss": 0.1017,
      "step": 5550
    },
    {
      "epoch": 4.055032585083273,
      "grad_norm": 3.2298331260681152,
      "learning_rate": 4.090554254488681e-06,
      "loss": 0.0913,
      "step": 5600
    },
    {
      "epoch": 4.091238233164374,
      "grad_norm": 9.836496353149414,
      "learning_rate": 3.934426229508197e-06,
      "loss": 0.0998,
      "step": 5650
    },
    {
      "epoch": 4.127443881245474,
      "grad_norm": 7.656777858734131,
      "learning_rate": 3.7782982045277127e-06,
      "loss": 0.095,
      "step": 5700
    },
    {
      "epoch": 4.163649529326575,
      "grad_norm": 5.9662981033325195,
      "learning_rate": 3.622170179547229e-06,
      "loss": 0.0743,
      "step": 5750
    },
    {
      "epoch": 4.1998551774076756,
      "grad_norm": 7.353404521942139,
      "learning_rate": 3.466042154566745e-06,
      "loss": 0.0884,
      "step": 5800
    },
    {
      "epoch": 4.236060825488776,
      "grad_norm": 19.34422492980957,
      "learning_rate": 3.309914129586261e-06,
      "loss": 0.0755,
      "step": 5850
    },
    {
      "epoch": 4.272266473569877,
      "grad_norm": 9.207098007202148,
      "learning_rate": 3.153786104605777e-06,
      "loss": 0.0782,
      "step": 5900
    },
    {
      "epoch": 4.308472121650977,
      "grad_norm": 2.412222385406494,
      "learning_rate": 2.997658079625293e-06,
      "loss": 0.0914,
      "step": 5950
    },
    {
      "epoch": 4.344677769732078,
      "grad_norm": 1.1603007316589355,
      "learning_rate": 2.8415300546448087e-06,
      "loss": 0.0876,
      "step": 6000
    },
    {
      "epoch": 4.380883417813179,
      "grad_norm": 6.466054916381836,
      "learning_rate": 2.685402029664325e-06,
      "loss": 0.092,
      "step": 6050
    },
    {
      "epoch": 4.417089065894279,
      "grad_norm": 1.9088143110275269,
      "learning_rate": 2.529274004683841e-06,
      "loss": 0.0917,
      "step": 6100
    },
    {
      "epoch": 4.45329471397538,
      "grad_norm": 8.525806427001953,
      "learning_rate": 2.373145979703357e-06,
      "loss": 0.0864,
      "step": 6150
    },
    {
      "epoch": 4.48950036205648,
      "grad_norm": 11.522340774536133,
      "learning_rate": 2.217017954722873e-06,
      "loss": 0.0927,
      "step": 6200
    },
    {
      "epoch": 4.525706010137581,
      "grad_norm": 15.100078582763672,
      "learning_rate": 2.060889929742389e-06,
      "loss": 0.0868,
      "step": 6250
    },
    {
      "epoch": 4.5619116582186825,
      "grad_norm": 2.1793887615203857,
      "learning_rate": 1.904761904761905e-06,
      "loss": 0.0973,
      "step": 6300
    },
    {
      "epoch": 4.598117306299783,
      "grad_norm": 2.7649710178375244,
      "learning_rate": 1.748633879781421e-06,
      "loss": 0.0881,
      "step": 6350
    },
    {
      "epoch": 4.634322954380884,
      "grad_norm": 11.381550788879395,
      "learning_rate": 1.592505854800937e-06,
      "loss": 0.0724,
      "step": 6400
    },
    {
      "epoch": 4.670528602461984,
      "grad_norm": 8.757795333862305,
      "learning_rate": 1.436377829820453e-06,
      "loss": 0.0997,
      "step": 6450
    },
    {
      "epoch": 4.706734250543085,
      "grad_norm": 0.9667290449142456,
      "learning_rate": 1.280249804839969e-06,
      "loss": 0.0957,
      "step": 6500
    },
    {
      "epoch": 4.7429398986241855,
      "grad_norm": 20.107637405395508,
      "learning_rate": 1.1241217798594848e-06,
      "loss": 0.1003,
      "step": 6550
    },
    {
      "epoch": 4.779145546705286,
      "grad_norm": 1.2307199239730835,
      "learning_rate": 9.67993754879001e-07,
      "loss": 0.0659,
      "step": 6600
    },
    {
      "epoch": 4.815351194786387,
      "grad_norm": 10.248339653015137,
      "learning_rate": 8.118657298985169e-07,
      "loss": 0.0885,
      "step": 6650
    },
    {
      "epoch": 4.851556842867487,
      "grad_norm": 1.34849214553833,
      "learning_rate": 6.557377049180328e-07,
      "loss": 0.0825,
      "step": 6700
    },
    {
      "epoch": 4.887762490948588,
      "grad_norm": 20.576927185058594,
      "learning_rate": 4.996096799375488e-07,
      "loss": 0.0946,
      "step": 6750
    },
    {
      "epoch": 4.9239681390296886,
      "grad_norm": 9.08693790435791,
      "learning_rate": 3.434816549570649e-07,
      "loss": 0.0818,
      "step": 6800
    },
    {
      "epoch": 4.960173787110789,
      "grad_norm": 12.554532051086426,
      "learning_rate": 1.8735362997658082e-07,
      "loss": 0.1211,
      "step": 6850
    },
    {
      "epoch": 4.99637943519189,
      "grad_norm": 1.5176588296890259,
      "learning_rate": 3.12256049960968e-08,
      "loss": 0.0906,
      "step": 6900
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9679974651457541,
      "eval_f1": 0.9647838214783822,
      "eval_loss": 0.099466472864151,
      "eval_precision": 0.9531519118153634,
      "eval_recall": 0.9767031415460642,
      "eval_runtime": 47.7657,
      "eval_samples_per_second": 264.29,
      "eval_steps_per_second": 8.27,
      "step": 6905
    }
  ],
  "logging_steps": 50,
  "max_steps": 6905,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.872849980899328e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
