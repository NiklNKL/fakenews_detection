{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 6905,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.036205648081100654,
      "grad_norm": 2.4779255390167236,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.6946,
      "step": 50
    },
    {
      "epoch": 0.07241129616220131,
      "grad_norm": 1.8308324813842773,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.6979,
      "step": 100
    },
    {
      "epoch": 0.10861694424330195,
      "grad_norm": 0.7525715231895447,
      "learning_rate": 6e-06,
      "loss": 0.6893,
      "step": 150
    },
    {
      "epoch": 0.14482259232440262,
      "grad_norm": 1.1827222108840942,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.6924,
      "step": 200
    },
    {
      "epoch": 0.18102824040550325,
      "grad_norm": 1.502022624015808,
      "learning_rate": 1e-05,
      "loss": 0.6917,
      "step": 250
    },
    {
      "epoch": 0.2172338884866039,
      "grad_norm": 0.9344965219497681,
      "learning_rate": 1.2e-05,
      "loss": 0.6792,
      "step": 300
    },
    {
      "epoch": 0.25343953656770457,
      "grad_norm": 2.1339786052703857,
      "learning_rate": 1.4e-05,
      "loss": 0.6575,
      "step": 350
    },
    {
      "epoch": 0.28964518464880523,
      "grad_norm": 1.1687980890274048,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.6288,
      "step": 400
    },
    {
      "epoch": 0.3258508327299059,
      "grad_norm": 2.7194933891296387,
      "learning_rate": 1.8e-05,
      "loss": 0.5501,
      "step": 450
    },
    {
      "epoch": 0.3620564808110065,
      "grad_norm": 2.6539673805236816,
      "learning_rate": 1.9960000000000002e-05,
      "loss": 0.5032,
      "step": 500
    },
    {
      "epoch": 0.39826212889210716,
      "grad_norm": 5.846429824829102,
      "learning_rate": 1.9846994535519127e-05,
      "loss": 0.4743,
      "step": 550
    },
    {
      "epoch": 0.4344677769732078,
      "grad_norm": 2.65356183052063,
      "learning_rate": 1.9690866510538645e-05,
      "loss": 0.447,
      "step": 600
    },
    {
      "epoch": 0.4706734250543085,
      "grad_norm": 2.422074556350708,
      "learning_rate": 1.953473848555816e-05,
      "loss": 0.4402,
      "step": 650
    },
    {
      "epoch": 0.5068790731354091,
      "grad_norm": 2.579153060913086,
      "learning_rate": 1.9378610460577677e-05,
      "loss": 0.4241,
      "step": 700
    },
    {
      "epoch": 0.5430847212165097,
      "grad_norm": 4.8465352058410645,
      "learning_rate": 1.922248243559719e-05,
      "loss": 0.4353,
      "step": 750
    },
    {
      "epoch": 0.5792903692976105,
      "grad_norm": 2.5837128162384033,
      "learning_rate": 1.906635441061671e-05,
      "loss": 0.3971,
      "step": 800
    },
    {
      "epoch": 0.6154960173787111,
      "grad_norm": 3.452571153640747,
      "learning_rate": 1.8910226385636224e-05,
      "loss": 0.3848,
      "step": 850
    },
    {
      "epoch": 0.6517016654598118,
      "grad_norm": 6.5714592933654785,
      "learning_rate": 1.8754098360655738e-05,
      "loss": 0.3709,
      "step": 900
    },
    {
      "epoch": 0.6879073135409124,
      "grad_norm": 4.177775859832764,
      "learning_rate": 1.8597970335675256e-05,
      "loss": 0.3434,
      "step": 950
    },
    {
      "epoch": 0.724112961622013,
      "grad_norm": 2.8227012157440186,
      "learning_rate": 1.844496487119438e-05,
      "loss": 0.3621,
      "step": 1000
    },
    {
      "epoch": 0.7603186097031137,
      "grad_norm": 5.43732213973999,
      "learning_rate": 1.82888368462139e-05,
      "loss": 0.3673,
      "step": 1050
    },
    {
      "epoch": 0.7965242577842143,
      "grad_norm": 11.777953147888184,
      "learning_rate": 1.8132708821233413e-05,
      "loss": 0.3611,
      "step": 1100
    },
    {
      "epoch": 0.832729905865315,
      "grad_norm": 3.7868857383728027,
      "learning_rate": 1.7976580796252928e-05,
      "loss": 0.3429,
      "step": 1150
    },
    {
      "epoch": 0.8689355539464156,
      "grad_norm": 3.316004514694214,
      "learning_rate": 1.7820452771272445e-05,
      "loss": 0.3329,
      "step": 1200
    },
    {
      "epoch": 0.9051412020275162,
      "grad_norm": 3.4521994590759277,
      "learning_rate": 1.766432474629196e-05,
      "loss": 0.3362,
      "step": 1250
    },
    {
      "epoch": 0.941346850108617,
      "grad_norm": 3.208091974258423,
      "learning_rate": 1.7508196721311478e-05,
      "loss": 0.3243,
      "step": 1300
    },
    {
      "epoch": 0.9775524981897176,
      "grad_norm": 5.038010597229004,
      "learning_rate": 1.7352068696330992e-05,
      "loss": 0.3239,
      "step": 1350
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8751584283903675,
      "eval_f1": 0.8493019697838975,
      "eval_loss": 0.31140953302383423,
      "eval_precision": 0.9267529215358932,
      "eval_recall": 0.7837980938933993,
      "eval_runtime": 69.6485,
      "eval_samples_per_second": 181.253,
      "eval_steps_per_second": 5.671,
      "step": 1381
    },
    {
      "epoch": 1.0137581462708183,
      "grad_norm": 9.33969497680664,
      "learning_rate": 1.719594067135051e-05,
      "loss": 0.3075,
      "step": 1400
    },
    {
      "epoch": 1.0499637943519189,
      "grad_norm": 3.2366819381713867,
      "learning_rate": 1.7039812646370024e-05,
      "loss": 0.2977,
      "step": 1450
    },
    {
      "epoch": 1.0861694424330195,
      "grad_norm": 7.008361339569092,
      "learning_rate": 1.688368462138954e-05,
      "loss": 0.2819,
      "step": 1500
    },
    {
      "epoch": 1.12237509051412,
      "grad_norm": 5.404018878936768,
      "learning_rate": 1.6727556596409056e-05,
      "loss": 0.3224,
      "step": 1550
    },
    {
      "epoch": 1.158580738595221,
      "grad_norm": 10.231833457946777,
      "learning_rate": 1.6571428571428574e-05,
      "loss": 0.2897,
      "step": 1600
    },
    {
      "epoch": 1.1947863866763215,
      "grad_norm": 2.6880083084106445,
      "learning_rate": 1.641530054644809e-05,
      "loss": 0.2989,
      "step": 1650
    },
    {
      "epoch": 1.2309920347574221,
      "grad_norm": 1.5684798955917358,
      "learning_rate": 1.6259172521467606e-05,
      "loss": 0.2632,
      "step": 1700
    },
    {
      "epoch": 1.2671976828385227,
      "grad_norm": 2.854947328567505,
      "learning_rate": 1.610304449648712e-05,
      "loss": 0.2831,
      "step": 1750
    },
    {
      "epoch": 1.3034033309196236,
      "grad_norm": 5.022585391998291,
      "learning_rate": 1.5946916471506638e-05,
      "loss": 0.2636,
      "step": 1800
    },
    {
      "epoch": 1.3396089790007242,
      "grad_norm": 5.4040656089782715,
      "learning_rate": 1.5790788446526153e-05,
      "loss": 0.2826,
      "step": 1850
    },
    {
      "epoch": 1.3758146270818248,
      "grad_norm": 5.235396385192871,
      "learning_rate": 1.563466042154567e-05,
      "loss": 0.2854,
      "step": 1900
    },
    {
      "epoch": 1.4120202751629254,
      "grad_norm": 9.9867525100708,
      "learning_rate": 1.5478532396565185e-05,
      "loss": 0.27,
      "step": 1950
    },
    {
      "epoch": 1.448225923244026,
      "grad_norm": 11.462158203125,
      "learning_rate": 1.53224043715847e-05,
      "loss": 0.2597,
      "step": 2000
    },
    {
      "epoch": 1.4844315713251266,
      "grad_norm": 4.693838119506836,
      "learning_rate": 1.5166276346604217e-05,
      "loss": 0.2806,
      "step": 2050
    },
    {
      "epoch": 1.5206372194062274,
      "grad_norm": 4.454129695892334,
      "learning_rate": 1.5010148321623731e-05,
      "loss": 0.2602,
      "step": 2100
    },
    {
      "epoch": 1.556842867487328,
      "grad_norm": 5.572049140930176,
      "learning_rate": 1.4854020296643247e-05,
      "loss": 0.2582,
      "step": 2150
    },
    {
      "epoch": 1.5930485155684286,
      "grad_norm": 8.808403015136719,
      "learning_rate": 1.4697892271662763e-05,
      "loss": 0.2624,
      "step": 2200
    },
    {
      "epoch": 1.6292541636495295,
      "grad_norm": 5.600014686584473,
      "learning_rate": 1.4541764246682281e-05,
      "loss": 0.2225,
      "step": 2250
    },
    {
      "epoch": 1.66545981173063,
      "grad_norm": 12.365453720092773,
      "learning_rate": 1.4385636221701797e-05,
      "loss": 0.2601,
      "step": 2300
    },
    {
      "epoch": 1.7016654598117307,
      "grad_norm": 4.285449981689453,
      "learning_rate": 1.4229508196721313e-05,
      "loss": 0.2335,
      "step": 2350
    },
    {
      "epoch": 1.7378711078928313,
      "grad_norm": 10.295186042785645,
      "learning_rate": 1.407338017174083e-05,
      "loss": 0.2388,
      "step": 2400
    },
    {
      "epoch": 1.7740767559739319,
      "grad_norm": 5.341221332550049,
      "learning_rate": 1.3917252146760345e-05,
      "loss": 0.1948,
      "step": 2450
    },
    {
      "epoch": 1.8102824040550325,
      "grad_norm": 7.069558620452881,
      "learning_rate": 1.3761124121779862e-05,
      "loss": 0.2252,
      "step": 2500
    },
    {
      "epoch": 1.846488052136133,
      "grad_norm": 5.411576271057129,
      "learning_rate": 1.3604996096799376e-05,
      "loss": 0.2357,
      "step": 2550
    },
    {
      "epoch": 1.882693700217234,
      "grad_norm": 4.228413105010986,
      "learning_rate": 1.3448868071818892e-05,
      "loss": 0.2342,
      "step": 2600
    },
    {
      "epoch": 1.9188993482983345,
      "grad_norm": 4.77107048034668,
      "learning_rate": 1.3292740046838408e-05,
      "loss": 0.2183,
      "step": 2650
    },
    {
      "epoch": 1.9551049963794354,
      "grad_norm": 5.508509635925293,
      "learning_rate": 1.3136612021857924e-05,
      "loss": 0.2251,
      "step": 2700
    },
    {
      "epoch": 1.991310644460536,
      "grad_norm": 12.419785499572754,
      "learning_rate": 1.298048399687744e-05,
      "loss": 0.2245,
      "step": 2750
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9237959442332065,
      "eval_f1": 0.9135047653299766,
      "eval_loss": 0.19507160782814026,
      "eval_precision": 0.9310850439882697,
      "eval_recall": 0.8965760677726792,
      "eval_runtime": 67.7814,
      "eval_samples_per_second": 186.246,
      "eval_steps_per_second": 5.828,
      "step": 2762
    },
    {
      "epoch": 2.0275162925416366,
      "grad_norm": 4.263272285461426,
      "learning_rate": 1.2824355971896956e-05,
      "loss": 0.2311,
      "step": 2800
    },
    {
      "epoch": 2.063721940622737,
      "grad_norm": 7.000010967254639,
      "learning_rate": 1.2668227946916472e-05,
      "loss": 0.2022,
      "step": 2850
    },
    {
      "epoch": 2.0999275887038378,
      "grad_norm": 8.38765811920166,
      "learning_rate": 1.251209992193599e-05,
      "loss": 0.182,
      "step": 2900
    },
    {
      "epoch": 2.1361332367849384,
      "grad_norm": 7.262079238891602,
      "learning_rate": 1.2355971896955506e-05,
      "loss": 0.1833,
      "step": 2950
    },
    {
      "epoch": 2.172338884866039,
      "grad_norm": 10.57972240447998,
      "learning_rate": 1.219984387197502e-05,
      "loss": 0.1921,
      "step": 3000
    },
    {
      "epoch": 2.2085445329471396,
      "grad_norm": 4.615559101104736,
      "learning_rate": 1.2043715846994537e-05,
      "loss": 0.1998,
      "step": 3050
    },
    {
      "epoch": 2.24475018102824,
      "grad_norm": 3.643380641937256,
      "learning_rate": 1.1887587822014053e-05,
      "loss": 0.2052,
      "step": 3100
    },
    {
      "epoch": 2.2809558291093412,
      "grad_norm": 17.189767837524414,
      "learning_rate": 1.1731459797033569e-05,
      "loss": 0.1956,
      "step": 3150
    },
    {
      "epoch": 2.317161477190442,
      "grad_norm": 5.118510723114014,
      "learning_rate": 1.1575331772053085e-05,
      "loss": 0.2141,
      "step": 3200
    },
    {
      "epoch": 2.3533671252715425,
      "grad_norm": 4.9700446128845215,
      "learning_rate": 1.1419203747072601e-05,
      "loss": 0.2148,
      "step": 3250
    },
    {
      "epoch": 2.389572773352643,
      "grad_norm": 5.131172180175781,
      "learning_rate": 1.1263075722092115e-05,
      "loss": 0.1954,
      "step": 3300
    },
    {
      "epoch": 2.4257784214337437,
      "grad_norm": 5.14267635345459,
      "learning_rate": 1.1106947697111631e-05,
      "loss": 0.2022,
      "step": 3350
    },
    {
      "epoch": 2.4619840695148443,
      "grad_norm": 4.046318054199219,
      "learning_rate": 1.0950819672131147e-05,
      "loss": 0.177,
      "step": 3400
    },
    {
      "epoch": 2.498189717595945,
      "grad_norm": 2.3263020515441895,
      "learning_rate": 1.0794691647150663e-05,
      "loss": 0.1994,
      "step": 3450
    },
    {
      "epoch": 2.5343953656770455,
      "grad_norm": Infinity,
      "learning_rate": 1.064168618266979e-05,
      "loss": 0.1789,
      "step": 3500
    },
    {
      "epoch": 2.5706010137581465,
      "grad_norm": 12.714263916015625,
      "learning_rate": 1.0485558157689307e-05,
      "loss": 0.1792,
      "step": 3550
    },
    {
      "epoch": 2.606806661839247,
      "grad_norm": 10.437746047973633,
      "learning_rate": 1.0329430132708823e-05,
      "loss": 0.1835,
      "step": 3600
    },
    {
      "epoch": 2.6430123099203477,
      "grad_norm": 5.025437355041504,
      "learning_rate": 1.0173302107728337e-05,
      "loss": 0.1907,
      "step": 3650
    },
    {
      "epoch": 2.6792179580014484,
      "grad_norm": 5.637934684753418,
      "learning_rate": 1.0017174082747853e-05,
      "loss": 0.1832,
      "step": 3700
    },
    {
      "epoch": 2.715423606082549,
      "grad_norm": 3.841663122177124,
      "learning_rate": 9.861046057767371e-06,
      "loss": 0.1775,
      "step": 3750
    },
    {
      "epoch": 2.7516292541636496,
      "grad_norm": 3.1035706996917725,
      "learning_rate": 9.704918032786887e-06,
      "loss": 0.1756,
      "step": 3800
    },
    {
      "epoch": 2.78783490224475,
      "grad_norm": 15.501611709594727,
      "learning_rate": 9.548790007806401e-06,
      "loss": 0.1647,
      "step": 3850
    },
    {
      "epoch": 2.8240405503258508,
      "grad_norm": 7.656874179840088,
      "learning_rate": 9.392661982825918e-06,
      "loss": 0.1385,
      "step": 3900
    },
    {
      "epoch": 2.8602461984069514,
      "grad_norm": 4.738018989562988,
      "learning_rate": 9.236533957845434e-06,
      "loss": 0.153,
      "step": 3950
    },
    {
      "epoch": 2.896451846488052,
      "grad_norm": 7.858196258544922,
      "learning_rate": 9.08040593286495e-06,
      "loss": 0.1679,
      "step": 4000
    },
    {
      "epoch": 2.9326574945691526,
      "grad_norm": 4.84235954284668,
      "learning_rate": 8.924277907884466e-06,
      "loss": 0.163,
      "step": 4050
    },
    {
      "epoch": 2.968863142650253,
      "grad_norm": 8.711877822875977,
      "learning_rate": 8.768149882903982e-06,
      "loss": 0.1954,
      "step": 4100
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9425697084917617,
      "eval_f1": 0.9363979296429511,
      "eval_loss": 0.15163710713386536,
      "eval_precision": 0.9309262166405023,
      "eval_recall": 0.9419343452170844,
      "eval_runtime": 72.9164,
      "eval_samples_per_second": 173.13,
      "eval_steps_per_second": 5.417,
      "step": 4143
    },
    {
      "epoch": 3.0050687907313542,
      "grad_norm": 4.664431571960449,
      "learning_rate": 8.612021857923498e-06,
      "loss": 0.1558,
      "step": 4150
    },
    {
      "epoch": 3.041274438812455,
      "grad_norm": 6.879093170166016,
      "learning_rate": 8.455893832943014e-06,
      "loss": 0.1671,
      "step": 4200
    },
    {
      "epoch": 3.0774800868935555,
      "grad_norm": 8.884014129638672,
      "learning_rate": 8.29976580796253e-06,
      "loss": 0.1291,
      "step": 4250
    },
    {
      "epoch": 3.113685734974656,
      "grad_norm": 4.3247551918029785,
      "learning_rate": 8.143637782982046e-06,
      "loss": 0.1948,
      "step": 4300
    },
    {
      "epoch": 3.1498913830557567,
      "grad_norm": 4.446303367614746,
      "learning_rate": 7.987509758001562e-06,
      "loss": 0.1615,
      "step": 4350
    },
    {
      "epoch": 3.1860970311368573,
      "grad_norm": 7.8431220054626465,
      "learning_rate": 7.831381733021078e-06,
      "loss": 0.1615,
      "step": 4400
    },
    {
      "epoch": 3.222302679217958,
      "grad_norm": 1.132874846458435,
      "learning_rate": 7.675253708040594e-06,
      "loss": 0.1523,
      "step": 4450
    },
    {
      "epoch": 3.2585083272990585,
      "grad_norm": 9.64550495147705,
      "learning_rate": 7.51912568306011e-06,
      "loss": 0.1603,
      "step": 4500
    },
    {
      "epoch": 3.2947139753801595,
      "grad_norm": 11.095662117004395,
      "learning_rate": 7.362997658079626e-06,
      "loss": 0.1663,
      "step": 4550
    },
    {
      "epoch": 3.33091962346126,
      "grad_norm": 21.81096839904785,
      "learning_rate": 7.206869633099142e-06,
      "loss": 0.1558,
      "step": 4600
    },
    {
      "epoch": 3.3671252715423607,
      "grad_norm": 8.838411331176758,
      "learning_rate": 7.050741608118658e-06,
      "loss": 0.1462,
      "step": 4650
    },
    {
      "epoch": 3.4033309196234613,
      "grad_norm": 8.611992835998535,
      "learning_rate": 6.894613583138175e-06,
      "loss": 0.1497,
      "step": 4700
    },
    {
      "epoch": 3.439536567704562,
      "grad_norm": 5.764431953430176,
      "learning_rate": 6.73848555815769e-06,
      "loss": 0.1336,
      "step": 4750
    },
    {
      "epoch": 3.4757422157856626,
      "grad_norm": 8.891448020935059,
      "learning_rate": 6.582357533177206e-06,
      "loss": 0.1425,
      "step": 4800
    },
    {
      "epoch": 3.511947863866763,
      "grad_norm": 10.815598487854004,
      "learning_rate": 6.426229508196722e-06,
      "loss": 0.1746,
      "step": 4850
    },
    {
      "epoch": 3.5481535119478638,
      "grad_norm": 5.484329700469971,
      "learning_rate": 6.270101483216238e-06,
      "loss": 0.1611,
      "step": 4900
    },
    {
      "epoch": 3.5843591600289644,
      "grad_norm": 11.175058364868164,
      "learning_rate": 6.113973458235753e-06,
      "loss": 0.1517,
      "step": 4950
    },
    {
      "epoch": 3.620564808110065,
      "grad_norm": 4.568338394165039,
      "learning_rate": 5.957845433255269e-06,
      "loss": 0.1343,
      "step": 5000
    },
    {
      "epoch": 3.6567704561911656,
      "grad_norm": 6.708088397979736,
      "learning_rate": 5.801717408274786e-06,
      "loss": 0.1405,
      "step": 5050
    },
    {
      "epoch": 3.6929761042722666,
      "grad_norm": 13.324563980102539,
      "learning_rate": 5.645589383294302e-06,
      "loss": 0.1491,
      "step": 5100
    },
    {
      "epoch": 3.7291817523533672,
      "grad_norm": 13.808292388916016,
      "learning_rate": 5.489461358313818e-06,
      "loss": 0.1454,
      "step": 5150
    },
    {
      "epoch": 3.765387400434468,
      "grad_norm": 17.761585235595703,
      "learning_rate": 5.333333333333334e-06,
      "loss": 0.1356,
      "step": 5200
    },
    {
      "epoch": 3.8015930485155685,
      "grad_norm": 12.278572082519531,
      "learning_rate": 5.17720530835285e-06,
      "loss": 0.1685,
      "step": 5250
    },
    {
      "epoch": 3.837798696596669,
      "grad_norm": 7.050669193267822,
      "learning_rate": 5.021077283372365e-06,
      "loss": 0.1658,
      "step": 5300
    },
    {
      "epoch": 3.8740043446777697,
      "grad_norm": 7.800834655761719,
      "learning_rate": 4.864949258391882e-06,
      "loss": 0.1568,
      "step": 5350
    },
    {
      "epoch": 3.9102099927588703,
      "grad_norm": 4.648797512054443,
      "learning_rate": 4.708821233411398e-06,
      "loss": 0.1439,
      "step": 5400
    },
    {
      "epoch": 3.946415640839971,
      "grad_norm": 14.712217330932617,
      "learning_rate": 4.552693208430914e-06,
      "loss": 0.1555,
      "step": 5450
    },
    {
      "epoch": 3.982621288921072,
      "grad_norm": 6.089963912963867,
      "learning_rate": 4.39656518345043e-06,
      "loss": 0.148,
      "step": 5500
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9480354879594424,
      "eval_f1": 0.942090395480226,
      "eval_loss": 0.1354600042104721,
      "eval_precision": 0.9424231720240198,
      "eval_recall": 0.9417578538651606,
      "eval_runtime": 64.077,
      "eval_samples_per_second": 197.013,
      "eval_steps_per_second": 6.164,
      "step": 5524
    },
    {
      "epoch": 4.0188269370021725,
      "grad_norm": 7.004157066345215,
      "learning_rate": 4.240437158469945e-06,
      "loss": 0.1405,
      "step": 5550
    },
    {
      "epoch": 4.055032585083273,
      "grad_norm": 6.390842437744141,
      "learning_rate": 4.084309133489462e-06,
      "loss": 0.1092,
      "step": 5600
    },
    {
      "epoch": 4.091238233164374,
      "grad_norm": 4.020087242126465,
      "learning_rate": 3.9281811085089774e-06,
      "loss": 0.1323,
      "step": 5650
    },
    {
      "epoch": 4.127443881245474,
      "grad_norm": 4.0711750984191895,
      "learning_rate": 3.7720530835284935e-06,
      "loss": 0.138,
      "step": 5700
    },
    {
      "epoch": 4.163649529326575,
      "grad_norm": 7.786571979522705,
      "learning_rate": 3.61592505854801e-06,
      "loss": 0.1427,
      "step": 5750
    },
    {
      "epoch": 4.1998551774076756,
      "grad_norm": 6.110814094543457,
      "learning_rate": 3.4597970335675257e-06,
      "loss": 0.1453,
      "step": 5800
    },
    {
      "epoch": 4.236060825488776,
      "grad_norm": 5.606966018676758,
      "learning_rate": 3.3036690085870417e-06,
      "loss": 0.1434,
      "step": 5850
    },
    {
      "epoch": 4.272266473569877,
      "grad_norm": 17.429201126098633,
      "learning_rate": 3.147540983606558e-06,
      "loss": 0.1543,
      "step": 5900
    },
    {
      "epoch": 4.308472121650977,
      "grad_norm": 5.805938720703125,
      "learning_rate": 2.991412958626074e-06,
      "loss": 0.1464,
      "step": 5950
    },
    {
      "epoch": 4.344677769732078,
      "grad_norm": 2.9236438274383545,
      "learning_rate": 2.8352849336455895e-06,
      "loss": 0.1245,
      "step": 6000
    },
    {
      "epoch": 4.380883417813179,
      "grad_norm": 9.980181694030762,
      "learning_rate": 2.679156908665105e-06,
      "loss": 0.1522,
      "step": 6050
    },
    {
      "epoch": 4.417089065894279,
      "grad_norm": 11.515190124511719,
      "learning_rate": 2.5230288836846217e-06,
      "loss": 0.164,
      "step": 6100
    },
    {
      "epoch": 4.45329471397538,
      "grad_norm": 7.851841926574707,
      "learning_rate": 2.3669008587041377e-06,
      "loss": 0.1407,
      "step": 6150
    },
    {
      "epoch": 4.48950036205648,
      "grad_norm": 3.583146810531616,
      "learning_rate": 2.210772833723654e-06,
      "loss": 0.1359,
      "step": 6200
    },
    {
      "epoch": 4.525706010137581,
      "grad_norm": 13.369945526123047,
      "learning_rate": 2.0546448087431695e-06,
      "loss": 0.1293,
      "step": 6250
    },
    {
      "epoch": 4.5619116582186825,
      "grad_norm": 6.89902925491333,
      "learning_rate": 1.8985167837626855e-06,
      "loss": 0.1461,
      "step": 6300
    },
    {
      "epoch": 4.598117306299783,
      "grad_norm": 9.93670654296875,
      "learning_rate": 1.7423887587822016e-06,
      "loss": 0.1679,
      "step": 6350
    },
    {
      "epoch": 4.634322954380884,
      "grad_norm": 4.249425411224365,
      "learning_rate": 1.5862607338017175e-06,
      "loss": 0.1285,
      "step": 6400
    },
    {
      "epoch": 4.670528602461984,
      "grad_norm": 6.114865303039551,
      "learning_rate": 1.4301327088212335e-06,
      "loss": 0.1394,
      "step": 6450
    },
    {
      "epoch": 4.706734250543085,
      "grad_norm": 12.489503860473633,
      "learning_rate": 1.2740046838407496e-06,
      "loss": 0.1624,
      "step": 6500
    },
    {
      "epoch": 4.7429398986241855,
      "grad_norm": 6.35105037689209,
      "learning_rate": 1.1178766588602655e-06,
      "loss": 0.1566,
      "step": 6550
    },
    {
      "epoch": 4.779145546705286,
      "grad_norm": 10.297662734985352,
      "learning_rate": 9.617486338797815e-07,
      "loss": 0.1337,
      "step": 6600
    },
    {
      "epoch": 4.815351194786387,
      "grad_norm": 10.240817070007324,
      "learning_rate": 8.056206088992975e-07,
      "loss": 0.1527,
      "step": 6650
    },
    {
      "epoch": 4.851556842867487,
      "grad_norm": 10.465683937072754,
      "learning_rate": 6.494925839188135e-07,
      "loss": 0.1146,
      "step": 6700
    },
    {
      "epoch": 4.887762490948588,
      "grad_norm": 0.9008633494377136,
      "learning_rate": 4.933645589383295e-07,
      "loss": 0.1198,
      "step": 6750
    },
    {
      "epoch": 4.9239681390296886,
      "grad_norm": 15.461284637451172,
      "learning_rate": 3.3723653395784544e-07,
      "loss": 0.1383,
      "step": 6800
    },
    {
      "epoch": 4.960173787110789,
      "grad_norm": 3.3102684020996094,
      "learning_rate": 1.8110850897736146e-07,
      "loss": 0.1345,
      "step": 6850
    },
    {
      "epoch": 4.99637943519189,
      "grad_norm": 13.184075355529785,
      "learning_rate": 2.498048399687744e-08,
      "loss": 0.1285,
      "step": 6900
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9504119138149556,
      "eval_f1": 0.9448749559704122,
      "eval_loss": 0.1303231567144394,
      "eval_precision": 0.9428822495606327,
      "eval_recall": 0.9468761030709495,
      "eval_runtime": 64.7652,
      "eval_samples_per_second": 194.92,
      "eval_steps_per_second": 6.099,
      "step": 6905
    }
  ],
  "logging_steps": 50,
  "max_steps": 6905,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.83276849569792e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
